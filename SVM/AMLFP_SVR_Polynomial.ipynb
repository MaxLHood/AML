{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn\n",
    "!pip install keras\n",
    "!pip install tensorflow\n",
    "\n",
    "from xml.etree.ElementTree import PI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings \n",
    "import os\n",
    "import random\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import collections\n",
    "from keras.preprocessing.image import load_img\n",
    "from matplotlib.pyplot import figure\n",
    "from tensorflow.python.client import device_lib\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from keras import Sequential\n",
    "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout\n",
    "from keras import backend as K\n",
    "import zipfile\n",
    "#with zipfile.ZipFile(\"./petfinder-pawpularity-score/train.zip\", 'r') as zip_ref:\n",
    "    #zip_ref.extractall(\"./petfinder-pawpularity-score/train\")\n",
    "\n",
    "print(device_lib.list_local_devices())\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mypath = \"./petfinder-pawpularity-score\"\n",
    "files = [os.path.splitext(filename)[0] for filename in os.listdir(mypath + \"/train/train\")]\n",
    "\n",
    "filetr = open(mypath + \"/train.csv\")\n",
    "csvreadertr = csv.reader(filetr)\n",
    "\n",
    "tr_data = []\n",
    "for row in csvreadertr:\n",
    "    tr_data.append((row[0], row[13]))\n",
    "del tr_data[0]\n",
    "\n",
    "assert(collections.Counter(list(zip(*tr_data))[0]) == collections.Counter(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['images'] = files\n",
    "df['label'] = list(zip(*tr_data))[1]\n",
    "df['label'] = df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize = (15, 6), dpi = 150)\n",
    "\n",
    "temp = df['images']\n",
    "start = random.randint(0, len(temp))\n",
    "files = temp[start:start+25]\n",
    "\n",
    "#TODO: figure out how to put ratings beneath each image\n",
    "ratings = []\n",
    "for index,file in enumerate(files):    \n",
    "    plt.subplot(5,5,index+1)\n",
    "    img = load_img(mypath + \"/train/train/\" + file + \".jpg\")\n",
    "    img = np.array(img)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    ratings.append(np.array(df['label'][df['images'] == file])[0])\n",
    "\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize = (15, 6), dpi = 150)\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.histplot(df, x = 'label', bins = 100, kde = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df[(df['label'] < 100)]\n",
    "figure(figsize = (15, 6), dpi = 150)\n",
    "sns.set(style=\"darkgrid\")\n",
    "ax = sns.histplot(df, x = 'label', bins = 99, kde = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['label'] == 5])\n",
    "print(df[df['label'] == 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['images'] = mypath + \"/train/train/\" + df['images'] + \".jpg\" \n",
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train[train['label'] == 100])\n",
    "print(test[test['label'] == 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[(train['label'] < 100) & (train['label'] > 5)]\n",
    "print(train[train['label'] == 100])\n",
    "print(test[test['label'] == 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['label'] = df['label'].astype('str')\n",
    "#train['label'] = train['label'].astype('str')\n",
    "#test['label'] = test['label'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data generator for the images\n",
    "# splitting into testing and training data\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_generator = ImageDataGenerator(\n",
    "    rescale = 1./255, # normalize the image \n",
    "    rotation_range = 360, # augmentation of images (helps to avoid overfitting)\n",
    "    width_shift_range=0.35,\n",
    "    height_shift_range=0.35,\n",
    "    shear_range = 0.35,\n",
    "    zoom_range = 0.35,\n",
    "    horizontal_flip = True,\n",
    "    vertical_flip = True,\n",
    "    fill_mode = 'nearest',\n",
    ")\n",
    "\n",
    "val_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# TODO: can't seem to find documentation on what target_size does under hood\n",
    "# from source code, the 'dataframe' argument is the dataframe of full image paths\n",
    "train_iterator = train_generator.flow_from_dataframe(\n",
    "    train, \n",
    "    x_col='images', \n",
    "    y_col='label', \n",
    "    target_size=(128,128), \n",
    "    batch_size=64, \n",
    "    class_mode='raw'\n",
    ")\n",
    "\n",
    "val_iterator = val_generator.flow_from_dataframe(\n",
    "    test, \n",
    "    x_col='images', \n",
    "    y_col='label', \n",
    "    target_size=(128,128), \n",
    "    batch_size=64, \n",
    "    class_mode='raw'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#print(np.array(train_iterator[123][0]).shape)\n",
    "#train_iterator[0][1][0][0][0]\n",
    "testflat = np.array(train_iterator[0][0])\n",
    "print(testflat.shape)\n",
    "#print(testflat_f.shape)\n",
    "\n",
    "counter = 0\n",
    "stack = None\n",
    "super = None\n",
    "for s in train_iterator:    \n",
    "    testflat = s[0]\n",
    "    if (counter == 3000):\n",
    "        break\n",
    "    for b in testflat:\n",
    "        #counter = counter + 1\n",
    "        if (stack is None):\n",
    "            stack = b.flatten()\n",
    "        else: stack = np.vstack((stack, b.flatten()))\n",
    "        print(stack.shape)\n",
    "    if (super is None):\n",
    "            super = stack\n",
    "    else: super = np.vstack((super, stack))\n",
    "    counter = counter + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np_array = np.zeros(7502*128*128*3)\n",
    "x_np_array = np.reshape(x_np_array, (7502, 49152))\n",
    "#print(x_np_array.shape)\n",
    "#print(x_np_array)\n",
    "\n",
    "y_np_array = np.zeros(7502)\n",
    "y_np_array = np.reshape(y_np_array, (7502, 1))\n",
    "print(y_np_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xv_np_array = np.zeros(1983*128*128*3)\n",
    "xv_np_array = np.reshape(xv_np_array, (1983, 49152))\n",
    "#print(x_np_array.shape)\n",
    "#print(x_np_array)\n",
    "\n",
    "yv_np_array = np.zeros(1983)\n",
    "yv_np_array = np.reshape(yv_np_array, (1983, 1))\n",
    "print(yv_np_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for s in train_iterator:    \n",
    "    if counter == 7502:\n",
    "        break\n",
    "    batch = s[0]\n",
    "    batch_labels = s[1]\n",
    "    \n",
    "    #print(batch.shape)\n",
    "    #print(batch_labels.shape)\n",
    "    #print(x_np_array.shape)\n",
    "    cardinality = batch.shape[0]       \n",
    "    print(\"batch size: \" + str(cardinality))\n",
    "\n",
    "    for c in range(cardinality):\n",
    "        print(\"c: \" + str(c))\n",
    "        x_np_array[counter] = batch[c].flatten()\n",
    "        y_np_array[counter] = batch_labels[c]             \n",
    "        print(\"counter: \" + str(counter))\n",
    "        counter = counter + 1    \n",
    "\n",
    "#print(y_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "\n",
    "for s in val_iterator:    \n",
    "    if counter == 1983:\n",
    "        break\n",
    "\n",
    "    batch = s[0]\n",
    "    batch_labels = s[1]\n",
    "   \n",
    "    cardinality = batch.shape[0]       \n",
    "    print(\"batch size: \" + str(cardinality))\n",
    "\n",
    "    for c in range(cardinality):\n",
    "        print(\"c: \" + str(c))\n",
    "        xv_np_array[counter] = batch[c].flatten()\n",
    "        yv_np_array[counter] = batch_labels[c]             \n",
    "        print(\"counter: \" + str(counter))\n",
    "        counter = counter + 1    \n",
    "\n",
    "#print(y_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.sum(y_np_array))\n",
    "#np.savetxt(\"pawp_train_flat.csv\", arr_re, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_np_array[0].reshape((128, 128, 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "print(\"foo\")\n",
    "svr_rbf = SVR(kernel='poly', C=0.2, gamma='scale', epsilon=0.1, tol=0.001, degree=5)\n",
    "fit = svr_rbf.fit(x_np_array, y_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rbf = fit.predict(x_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_rbf)\n",
    "yv = fit.predict(xv_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "rms = mean_squared_error(xv_np_array, y_v, squared=False)\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "model2 = Sequential([\n",
    "    Conv2D(64, (7,7), activation='relu', input_shape=(128,128,3)),\n",
    "    MaxPool2D((3,3)),\n",
    "    Conv2D(16, (5,5), activation='relu'),\n",
    "    MaxPool2D((3,3)),\n",
    "    Conv2D(16, (4,4), activation='relu'),\n",
    "    Conv2D(16, (2,2), activation='relu'),\n",
    "    #Conv2D(256, (2,2), activation='relu'),\n",
    "    MaxPool2D((2,2)),\n",
    "    Flatten(),\n",
    "    Dropout(rate = 0.25),    \n",
    "    Dense(2048, activation='sigmoid'),    \n",
    "    Dense(1, activation='linear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_rbf = SVR(kernel='poly', C=0.2, gamma='scale', epsilon=0.5, tol=0.001, degree=5)\n",
    "fit = svr_rbf.fit(x_np_array, y_np_array)\n",
    "y_rbf = fit.predict(x_np_array)\n",
    "plt.hist(y_np_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_rbf)\n",
    "yv = fit.predict(xv_np_array)\n",
    "rms = mean_squared_error(xv_np_array, y_v, squared=False)\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_rbf = SVR(kernel='poly', C=0.2, gamma='scale', epsilon=0.1, tol=0.001, degree=10)\n",
    "fit = svr_rbf.fit(x_np_array, y_np_array)\n",
    "y_rbf = fit.predict(x_np_array)\n",
    "plt.hist(y_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_rbf)\n",
    "yv = fit.predict(xv_np_array)\n",
    "rms = mean_squared_error(xv_np_array, y_v, squared=False)\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_rbf = SVR(kernel='poly', C=0.2, gamma='scale', epsilon=0.5, tol=0.001, degree=10)\n",
    "fit = svr_rbf.fit(x_np_array, y_np_array)\n",
    "y_rbf = fit.predict(x_np_array)\n",
    "plt.hist(y_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_rbf)\n",
    "yv = fit.predict(xv_np_array)\n",
    "rms = mean_squared_error(xv_np_array, y_v, squared=False)\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_rbf = SVR(kernel='poly', C=0.1, gamma='scale', epsilon=0.1, tol=0.001, degree=10)\n",
    "fit = svr_rbf.fit(x_np_array, y_np_array)\n",
    "y_rbf = fit.predict(x_np_array)\n",
    "plt.hist(y_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_rbf)\n",
    "yv = fit.predict(xv_np_array)\n",
    "rms = mean_squared_error(xv_np_array, y_v, squared=False)\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_rbf = SVR(kernel='poly', C=0.1, gamma='scale', epsilon=0.5, tol=0.001, degree=10)\n",
    "fit = svr_rbf.fit(x_np_array, y_np_array)\n",
    "y_rbf = fit.predict(x_np_array)\n",
    "plt.hist(y_np_array)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_rbf)\n",
    "yv = fit.predict(xv_np_array)\n",
    "rms = mean_squared_error(xv_np_array, y_v, squared=False)\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_rbf = SVR(kernel='poly', C=0.1, gamma='scale', epsilon=0.1, tol=0.001, degree=7)\n",
    "fit = svr_rbf.fit(x_np_array, y_np_array)\n",
    "y_rbf = fit.predict(x_np_array)\n",
    "plt.hist(y_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_rbf)\n",
    "yv = fit.predict(xv_np_array)\n",
    "rms = mean_squared_error(xv_np_array, y_v, squared=False)\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_rbf = SVR(kernel='poly', C=0.2, gamma='scale', epsilon=0.5, tol=0.001, degree=7)\n",
    "fit = svr_rbf.fit(x_np_array, y_np_array)\n",
    "y_rbf = fit.predict(x_np_array)\n",
    "plt.hist(y_np_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_rbf)\n",
    "yv = fit.predict(xv_np_array)\n",
    "rms = mean_squared_error(xv_np_array, y_v, squared=False)\n",
    "print(rms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv_np_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0fa304bdb0eea3d773cc9f52a1513385559618480ba34303c232a14f237ddd89"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
